%!TEX root = vorlage.tex
% Martin Thoma
\subsection{Quality measures for evaluation}\label{subsec:quality-measures}

A performance measure is a crucial part of any machine learning system, but
there are other measures of quality which matter when segmentation algorithms
are compared. This section gives an overview of those quality measures.


\subsubsection{Accuracy}
One way to compare segmentation algorithms is by the pixel-wise accuracy of the
segmentation they find (per-pixel rate) as done in many publications
\cite{shotton2006textonboost} (TODO: Name more). Taking the pixel-wise
classification accuracy only has two major drawbacks:

\begin{itemize}
    \item Tasks like segmenting images for self-driving cars have large regions
          which have one class. This makes achieving classification accuracies
          of more than \SI{30}{\percent} only with a priori knowledge possible.
    \item The manually labeled images could have a more coarse labeling. For
          example, a human classifier could have labeled a region as
          \enquote{car} and the algortihm could have split that region into
          the general \enquote{car} and the more specific \enquote{wheel of a
          car}
\end{itemize}

Another problem might be pixels which cannot be assigend one of the known
classes. For this reason, \cite{shotton2006textonboost} makes use of a void
class. This class gets completely ignored for all quality measures. Hence the
total number of pixels is assumed to be $\text{width} \cdot \text{height} - \text{nr of void pixels}$.

One way to deal with this problem is giving a confuscation matrix as done in
\cite{shotton2006textonboost}. However, this approach is not feasible if many
classes are given.

Let $k \in \mathbb{N}$ be the number of classes, $n_{ij} \in \mathbb{N}_0$ with
$i,j \in 1, \dot, k$ be the number of pixels which belong to class~$i$ and were
labeled as class~$j$. Let $t_i = \sum_{j=1}^k n_{ij}$ be the total number of
pixels of class $k$.

One accuracy measure is \textit{Normalized Probabilistic Rand} (NPR) index
which was introduced in \cite{unnikrishnan2005measure}.

Another measure was introduced by~\cite{celebi2009improved}. TODO: Explain it

Another framework is introduced by~\cite{jaber2010probabilistic}. TODO: Explain
it

\cite{long2014fully} makes use of three metrics:

\begin{itemize}
    \item pixel accuracy: $\sum_{i=1}^k \frac{n_{ii}}{\sum_{i=1}^k t_i}$
    \item mean accuracy: $\frac{1}{k} \cdot \sum_{i=1}^n \frac{n_{ii}}{t_i}$
    \item mean intersection over union: $\frac{1}{k} \cdot \sum_{i=1}^k \frac{n_{ii}}{t_i + \sum_{j=1}^k n_{ji}-n_{ii}}$
    \item frequency weighted intersection over union:
          ${({\sum_{p=1}^k t_p})}^{-1} \sum_i \frac{t_i n_{ii}}{t_i + \sum_{j=1}^k n_{ji} - n_{ii}}$
\end{itemize}

Several accuracy measures were suggested for non-semantic
segmentation,\cite{martin2001database} but the reason for creating them seems
to be to deal with the under-defined task description of non-semantic
segmentation. These accuracy measures try to deal with different levels of
coarsity of the segmentation. This is much less of a problem in semantic
segmentation.

$F$-measure is used by~\cite{cohen2015memory}.

\enquote{The reported statistic is the F-measure, the harmonic mean of the precision
and recall. This measure has the downside of considering only region boundaries
in- stead of the regions themselves. Since region difference is a quadratic
measure whereas boundary difference is a linear measure, small boundary
imperfections will affect the measure more than they necessarily should.} in
A Comparison of Image Segmentation Algorithms

See also: \cite{yang2012layered,tighe2014scene} correct if hypothesis and
ground trouth overlap by more than \SI{50}{\percent}.
Mention Precision, Recall, $F$-Score?

----

\cite{tighe2014scene} makes use of per-pixel rate and per-class rate.

\enquote{For our pixel labeling, consistent with [20], we report the
number of pixels correctly classified (per-pixel rate) and the
average of per-class rates. The per-pixel rate indicates how
well the system is doing on the large common classes, while
the average per-class rate is more affected by the smaller,
less common classes.}

TODO: How is per-class rate defined?


\subsubsection{Speed}\label{subsubsec:speed-quality-measure}
One obvious quality measure is speed. For many applications, this is a hard
requirement. For example, in the case of self-driving cars an algorithm which
classifies pixel as street or no-street and thus makes a semantic segmentation,
every image needs to be processed within
\SI{20}{\milli\second}~\cite{bittel2015pixel}.

TODO: Which categories are there?

TODO: Health informatics: Which times?

The \gls{CRF} approach presented in \cite{shotton2006textonboost} takes
approximately three minutes to segment per image on a \SI{2.1}{\giga\hertz}
machine with \SI{2}{\giga\byte} memory.


\subsubsection{Stability}\label{subsubsec:stability-quality-measure}
The stability of segmentation is a desirable quality measure. One the one hand,
there are some variants of images like slight bluring, gaussian noise and
similar which should not change the segmentation at all. Also, two images which
show a slight change in perspective should also only result in slight changes
in the segmentation.\cite{pantofaru2005comparison}

The other desirable stability criterium is parameter choice. If the
segmentation algorithm has hyperparameters, then slightly changing those should
also only result in minor differences of the resulting segmentations~\cite{pantofaru2005comparison}.


\subsubsection{Memory and Power usage}

Memory usage is important when segmentation algorithms get used in devices like
smartphones or cameras, or when the algorithms have to finish in a given
timeframe, run on the \gls{GPU} and consume so much memory for single image
segmentation that only the latest graphic cards can be used. However, no
publication we found mentioned the peak memory usage.

Power usage is an important design choice for algorithms which run on mobile
devices. Just like memory usage, it hasn't been reported in publications by
now.
