%!TEX root = vorlage.tex
% Marvin Teichmann

%TODO: Type of MLP
\section{Neural Networks for Segmentation}\label{sec:fcn}

As descripted in ... the computer vision community had great success in applying \Glspl{CNN} to image classification problems. There have been quite a lot of efford to adopt these results to semantic segmantation. This is done by viewing semantic segmantation as a pixel-level classificion problem. 

A recent break-through has been archived by Long, Shelhammer et. al with the design of Fully Convolutional Networks \cite{fcn}. 



 Inspired by these successes researchers have tried to benefit 

Regarding the successes of \Glspl{CNN} in image classification researches have started adopting these  



As described in \Cref{sec:tasks} Semantic Segmentation can be views as a spatial version of classification, where a classification model can be transfered into a segmentation model using a sliding window approach. In \glspl{CNN} sliding window can be carried out very efficiently. Most CNN based segmentation approaches are using this insight to build models on the shoulders of AlexNet and its deeper successors. 

\subsection{Sliding Window efficiency in CNNs}

%TODO: Directly copied from paper: overfeat

In contrast to many sliding-window approaches that compute an entire pipeline for each window that input one at a time, ConvNets are inherently efficient because they naturally share computations common to overlapping regions. 

%TODO: Directly copied from paper: overfeat

This is because the convolution properties are computational traceable. Let $F, G$ be given by its kernel functions $f,g$ with sizes $k,k'$ and stride $s,s'$, respectively. Than $F \circ G$ is obtained by convolution with $f \circ g$, which has kernel size $k + (k-1) s'$ using stride $s \cdot s'$. A classification ConvNet with input layer of size $k \times k$, output of size $1 \times 1$ therefore computes a convolution with kernel size $k^2$ and stride $s$ equal to the product of strides inside the network. If fully connected layer are transformed into convolutional layer (as descripted in \Cref{sec:fully_connected_layer}), it is possible to apply this network on an input image of size $n \times m$ with $n,m \geq k$ and to obtain an output equal to a sliding window with stride $s$. 

The main drawback of this method is, that the stride $s$ becomes quite large, e.g. $32$ when using VGG16. There are two approaches to overcome this problem:

\subsubsection{Shift-and-stitch} The idea of this approach is to feed each layer with stride $s$ with $s^2$ shifted versions of the input. This basically neglects the computational advantage of strides, but keeps the statistical relevant effects. Fast-scanning \cite{fast_scanning} descripes a trick to efficiently perform this computation.  This idea is used in several publications \cite{overfeat,huval}.

\subsubsection{Upsampling} Alternatively one can use 


 add deconvolution layer on top of the ConvNet architecture. This enables the network to learn to upsample the coarse representation obtained by the sliding-window. This approach is introduced in (cite) and since used in a variety of publications (SegNET, ...)

One advantage of the deconvolution approach is, that the original ConvNet can be trained using data labeled for the classification task, only the deconvolution layer .

\subsection{FCN}

A recent break-through has been achieved by Long, Shelhammer et. al \cite{fcn} by designing \gls{FCN} an architecture specifically framed towards semantic segmentation. Similar to the sliding-window based approaches, they are using a classification network to obtain a low-resolution feature map containing spatial informations about the objects. But opposed to earlier approaches they are using a trainable deconvolution layer to upsample this feature map.


\subsubsection{Deconvolution} Todo: detailed explanation of deconvolution



\subsubsection{Skip-Architecture}



\subsubsection{Transfer Learning} One of the strengthes of the FCN approach is the use of transfer learning. Training is done in two steps. First the classification network is done using weakly annotated data (i.e. classification labels). Afterwards the last layer of the architecture is replaced by a deconvolution layer. Only than the Network is fine-tuned on segmentation data. Usually weakly labeled data is much cheaper to obtain than fully labeled segmentation data making this approach very attractive for a lot of applications.


In the publication several the FCN approach was applied to AlexNet, VGG16 and GoogLeNet. The best results where achieved on VGG16. A possible explanation for this is, that VGG16 uses stride and pooling most cautiously perserving lots of spatial information.




\subsection{Extensions of FCN}

Several extensions of FCN have been proposed. All of are based on VGG16. The main differentses between the approaches are how the how upsambling is performed. 

Several Authors have combined FCNs with CRFs very succesfully. Zheng et. al \cite{CRF1} and Chen et at. \cite{CRF2} improved the results of Long et. al \cite{fcn} by applying \gls{CRF} on top of the FCN architecture. 

\cite{deconv1} and \cite{segnet} proposed a slightly different approach. The designed a deep decoding network to performe the upsampling. Where each layer of the decoding network corresponds to a pooling layer of the VGG network. The upsampling itselfe is not trained but computed directly using the max pooling indezies. Trained convolution layers are used between the upsampling operations to refine the results. The main downside of this approaches is, that the networks need a large amount of strong labeled data as they are fully trained end-to-end. This problem is relaxed in \cite{decoupled}, by introducing transfer-learning to deep deconvolution networks.





