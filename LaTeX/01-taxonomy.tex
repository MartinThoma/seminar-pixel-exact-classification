%!TEX root = vorlage.tex

\section{Taxonomy of Segmentation Algorithms}\label{sec:taxonomy}
The computer vision community has published a wide range of segmentation
algorithms so far. Those algorithms can be grouped by the kind of data they
operate on and the kind of segmentation they are able to produce.

The following subsections will give four different criteria by which
segmentation algorithms can be classified.

This survey describes fixed-class (see \cref{subsec:allowed-classes}),
single-class affiliation (see \cref{subsec:class-affiliation}) algorithms which
work on grayscale or colored single pixel images (see \cref{subsec:input-data})
in a completely automated, passive fashion (see \cref{subsec:operation-state}).


\subsection{Allowed classes}\label{subsec:allowed-classes}
Semantic segmentation is a classification task. As such, the classes on which
the algorithm is trained is a central design decision.

Most algorithms work with a fixed set of classes; some even only work on binary
classes like \textit{foreground vs
background}~\cite{4228537,carreira2010constrained} or \textit{street vs no
street}~\cite{bittel2015pixel}.

However, there are also unsupervised segmentation algorithms which do not
distinguish classes at all (see
\cref{subsec:unsupervised-traditional-segmentation}) as well as segmentation
algorithms which are able to recognize when they don't know a class. For
example, in~\cite{gould2008multi} a
\textbf{void class} was added for classes which were not in the training set.
Such a void class was also used in the MSRCv2 dataset (see
\cref{subsubsec:MSRCv2}) to make it possible to make more coarse segmentations
and thus having to spend less time annotating the image.


\subsection{Class affiliation of pixels}\label{subsec:class-affiliation}
Humans do an incredible job when looking at the world. For example, when we see
a glass of water standing on a table we can automatically say that there is the
glass and behind it the table, even if we only had a single image and were not
allowed to move. This means we simultaneously two labels to the coordinates of
the glass: Glass and table. Although there is much more work being done on
\textbf{single class affiliation} segmentation algorithms, there is a
publication about \textbf{multiple class affiliation}
segmentation~\cite{levin2008spectral}. Similarly, recent publications in
pixel-level object segmentation used layered models~\cite{yang2012layered}.

\goodbreak
\subsection{Input Data}\label{subsec:input-data}
The available data which can be used for the inference of a segmentation varies
by application.

\begin{itemize}
    \item \textbf{Grayscale vs colored}: Grayscale images are commonly used in
          medical imaging such as \gls{MR} imaging or ultrasonography whereas
          colored photographs are obviously widespread.
    \item \textbf{Excluding or including depth data}: RGB-D, sometimes also
          called range~\cite{hoover1996experimental} is available in robotics,
          autonomous cars and recently also in consumer electronics such as
          Microsoft Kinect~\cite{6190806}.
    \item \textbf{Single image vs stereo images vs co-segmentation}: Single
          image segmentation is the most wide-spread kind of segmentation, but
          using stereo images was already tried in~\cite{boykov2001fast}. It
          can be seen as a more natural way of segmentation as most mammals
          have two eyes. It can also be seen as being related to having
          depth data.\\
          Co-segmentation as in~\cite{1640859,collins2012random} is the problem
          of finding a consistent segmentation for multiple images. This problem
          can be seen in two ways: One the one hand, it can be seen as the problem
          of finding common objects in at least two images. On the other hand,
          every image after the first can be used as an additional source of
          information to find a meaningful segmentation. This idea can be
          extended to time series such as videos.
    \item \textbf{2D vs 3D}: Segmenting images is a 2D~segmentation task where
          the smallest unit is called a \textit{pixel}. In 3D data, such as
          volumetric X-ray CT images as they were used in~\cite{929615}, the
          smallest unit is called a voxel.
\end{itemize}


\subsection{Operation state}\label{subsec:operation-state}
The operation state of the classifying machine can either be \textbf{active} as
in~\cite{schiebener2011segmentation,schiebener2012discovery} where robots can
move objects to find a segmentation or \textbf{passive}, where the received
image cannot be influenced. Among the passive algorithms, some segment in a
completely \textbf{automatic} fashion, others work in an \textbf{interactive}
mode. One example would be a system where the user clicks on the background or
marks a coarse segmentation and the algorithm finds a fine-grained
segmentation.
\cite{boykov2000interactive,rother2004grabcut,protiere2007interactive}~describe
systems which work in an interactive mode.
